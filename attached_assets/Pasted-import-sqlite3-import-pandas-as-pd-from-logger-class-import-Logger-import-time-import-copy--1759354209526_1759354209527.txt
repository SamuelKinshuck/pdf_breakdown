import sqlite3
import pandas as pd
from logger_class import Logger
import time
import copy

# Configure logging to write to logfile.txt
logging = Logger("./output/logfile.txt")

RETRYABLE = ("locked", "readonly") 
def write_dataframe_to_sql(df: pd.DataFrame, table_name: str) -> None:
    """
    Writes a pandas DataFrame to a specified SQLite table.
    Appends the data if the table already exists.
    Retries if the DB is locked.
    """
    db_path = "./output/storage.db"
    max_retries = 3
    attempt = 0

    while attempt < max_retries:
        conn = None
        try:
            conn = sqlite3.connect(db_path)
            df.to_sql(table_name, conn, if_exists='append', index=False)
            # Success: return and do not retry
            return
        except sqlite3.OperationalError as e:
            # Check if it's a locked error
            if any(k in str(e).lower() for k in RETRYABLE):
                logging.error(
                    f"Database locked when writing DataFrame (attempt {attempt+1}/{max_retries}): {e}"
                )
                time.sleep(2)
                attempt += 1
            else:
                logging.exception("Non-locked error while writing DataFrame to SQL.")
                break
        except sqlite3.Error as e:
            # Catch other sqlite3 errors
            logging.exception(f"SQLite error while writing DataFrame: {e}")
            break
        finally:
            if conn:
                conn.close()

    logging.error("Exceeded maximum retries. Could not write DataFrame to SQL.")


# ---------------------------------------------------------------------- #
# Helper: very lightweight Python-type → SQLite-type mapping
# ---------------------------------------------------------------------- #
def _infer_sql_type(value):
    if isinstance(value, bool):
        return "INTEGER"
    if isinstance(value, int):
        return "INTEGER"
    if isinstance(value, float):
        return "REAL"
    if isinstance(value, (bytes, bytearray)):
        return "BLOB"
    return "TEXT"


def append_row_to_sql_table(row: dict, table_name: str) -> None:
    """
    Inserts a single row (dict of column:value) into `table_name` inside storage.db.
    • If the table does not exist, it is created with columns inferred from `row`.
    • If the table exists but is missing columns, they are added on-the-fly.
    • Retries transparently when the DB is locked.
    """

    db_path = "./output/storage.db"
    max_retries = 3
    attempt = 0
    to_insert = copy.deepcopy(row)

    # Flatten list/tuple under "options" (keep behaviour of original function)
    if "options" in to_insert and isinstance(to_insert["options"], (list, tuple)):
        to_insert["options"] = "; ".join(map(str, to_insert["options"]))


    while attempt < max_retries:
        conn = None
        try:
            conn = sqlite3.connect(db_path)
            cursor = conn.cursor()

            # ------------------------------------------------------------------
            # 1. Create table if it doesn't exist
            # ------------------------------------------------------------------
            cursor.execute(
                "SELECT name FROM sqlite_master WHERE type='table' AND name=?;",
                (table_name,),
            )
            table_exists = cursor.fetchone() is not None

            if not table_exists:
                # Build CREATE TABLE statement from current keys
                col_defs = ", ".join(
                    f"{col} {_infer_sql_type(val)}" for col, val in to_insert.items()
                )
                create_stmt = f"CREATE TABLE {table_name} ({col_defs});"
                cursor.execute(create_stmt)

            # ------------------------------------------------------------------
            # 2. Ensure every key in `to_insert` is a column
            # ------------------------------------------------------------------
            cursor.execute(f"PRAGMA table_info({table_name});")
            existing_cols = {row[1] for row in cursor.fetchall()}  # row[1] = col name

            for key in to_insert.keys() - existing_cols:
                col_type = _infer_sql_type(to_insert[key])
                cursor.execute(f"ALTER TABLE {table_name} ADD COLUMN {key} {col_type};")

            # ------------------------------------------------------------------
            # 3. Perform the INSERT
            # ------------------------------------------------------------------
            cols = ", ".join(to_insert.keys())
            placeholders = ", ".join("?" for _ in to_insert)
            values = tuple(to_insert.values())

            cursor.execute(
                f"INSERT INTO {table_name} ({cols}) VALUES ({placeholders});", values
            )
            conn.commit()
            return  # Success

        except sqlite3.OperationalError as e:
            # Retry only when the error is lock-related
            if any(k in str(e).lower() for k in RETRYABLE):
                attempt += 1
                logging.error(
                    f"Database locked when appending row (attempt {attempt}/{max_retries}): {e}"
                )
                time.sleep(2)
            else:
                logging.exception("Non-retryable OperationalError while appending row.")
                break
        except sqlite3.Error as e:
            logging.exception(f"SQLite error while appending row: {e}")
            break
        finally:
            if conn:
                conn.close()


    logging.error(f"Exceeded maximum retries. Could not append row to table '{table_name}'.")


def read_df_from_database(table_name: str) -> pd.DataFrame:
    """
    Reads an entire SQLite table into a pandas DataFrame.
    Retries if the DB is locked.
    """
    db_path = "./output/storage.db"
    max_retries = 3
    attempt = 0

    # In case of failure, return an empty DataFrame
    df = pd.DataFrame()

    while attempt < max_retries:
        conn = None
        try:
            conn = sqlite3.connect(db_path)
            cursor = conn.cursor()

            cursor.execute(f"SELECT * FROM {table_name}")
            rows = cursor.fetchall()
            columns = [desc[0] for desc in cursor.description]

            df = pd.DataFrame(rows, columns=columns)
            return df
        except sqlite3.OperationalError as e:
            if any(k in str(e).lower() for k in RETRYABLE):
                logging.error(
                    f"Database locked when reading table '{table_name}' "
                    f"(attempt {attempt+1}/{max_retries}): {e}"
                )
                time.sleep(2)
                attempt += 1
            else:
                logging.exception(f"Non-locked error while reading from table '{table_name}'.")
                break
        except sqlite3.Error as e:
            logging.exception(f"SQLite error while reading from table '{table_name}': {e}")
            break
        finally:
            if conn:
                conn.close()

    logging.error(f"Exceeded maximum retries. Could not read table '{table_name}'.")
    return df

def delete_table(table_name):
    db_path = "./output/storage.db"
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()

    cursor.execute(f"DROP TABLE IF EXISTS {table_name}")
    conn.close()

def delete_all_tables():
    conn = sqlite3.connect("./output/storage.db")  # Replace with your actual database file
    cursor = conn.cursor()

    # Fetch all table names
    cursor.execute("SELECT name FROM sqlite_master WHERE type='table';")
    tables = cursor.fetchall()

    # Drop each table
    for table_name in tables:
        print(f"Dropping table {table_name[0]}...")
        cursor.execute(f"DROP TABLE IF EXISTS {table_name[0]};")

    # Commit changes and close the connection
    conn.commit()
    conn.close()
    write_dataframe_to_sql(pd.DataFrame({'name': 'dummy'}, index=[0]), 'who_finished')


def delete_rows_by_name(name: str, table_name: str) -> None:
    """
    Deletes all rows from the specified table where the 'Name' column matches the given name.
    Retries if the database is locked.
    """
    db_path = "./output/storage.db"
    max_retries = 3
    attempt = 0

    while attempt < max_retries:
        conn = None
        try:
            conn = sqlite3.connect(db_path)
            cursor = conn.cursor()

            query = f"DELETE FROM {table_name} WHERE name = ?"
            cursor.execute(query, (name,))
            conn.commit()
            return  # Success
        except sqlite3.OperationalError as e:
            if any(k in str(e).lower() for k in RETRYABLE):
                logging.error(
                    f"Database locked when deleting rows (attempt {attempt+1}/{max_retries}): {e}"
                )
                time.sleep(2)
                attempt += 1
            else:
                logging.exception(f"Non-locked error while deleting rows from '{table_name}'.")
                break
        except sqlite3.Error as e:
            logging.exception(f"SQLite error while deleting rows: {e}")
            break
        finally:
            if conn:
                conn.close()

    logging.error(f"Exceeded maximum retries. Could not delete rows from '{table_name}' where Name = '{name}'.")